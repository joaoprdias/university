{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trabalho de Processamento de Big Data | Licenciatura em Ciência de Dados 2023/24 | CDB1**\n",
    "\n",
    "Docente: João Oliveira<br><br>\n",
    "\n",
    "- David Franco, nº110733\n",
    "\n",
    "- Felipe Pereira, nº110861\n",
    "\n",
    "- João Dias, nº110305\n",
    "\n",
    "- Samuel Ricardo, nº110884<br><br>\n",
    "\n",
    "https://www.kaggle.com/datasets/PROPPG-PPG/hourly-weather-surface-brazil-southeast-region\n",
    "\n",
    "*Version 9 (10.11 GB) | Created by John Holz | Data Update 2023/01/30*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos gerados no passo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import PipelineModel\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a sessão de Spark\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherBrazilModelingApplication\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 512) \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_stations.parquet\n",
      "classification-validation-set.parquet\n",
      "datasets_originais\n",
      "model-RandomForestRegression\n",
      "model-svm\n",
      "n1_trabalho_final_limpeza.ipynb\n",
      "n2_trabalho_final_analise_exploratoria.ipynb\n",
      "n3_trabalho_final_modelos.ipynb\n",
      "n4_trabalho_final_aplica_modelo.ipynb\n",
      "n5_trabalho_final_relatorio.ipynb\n",
      "pbd_projeto_2024.pdf\n",
      "pipeline-RandomForestRegression\n",
      "pipeline-svm\n",
      "regression-validation-set.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão da temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = spark.read.parquet(\"regression-validation-set.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados de validação do arquivo Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(\"model-RandomForestRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o pipeline treinado do disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- TotalHourlyPrecipitationMm: double (nullable = true)\n",
      " |-- HourlyStationLevelAtmosphericPressureMb: double (nullable = true)\n",
      " |-- LastHourMaxAtmosphericPressureMb: double (nullable = true)\n",
      " |-- LastHourMinAtmosphericPressureMb: double (nullable = true)\n",
      " |-- HourlyDryBulbAirTemperatureC: double (nullable = true)\n",
      " |-- DewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMaxDewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMinDewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMaxRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- LastHourMinRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- HourlyRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- HourlyWindDirectionRadiusDegrees: integer (nullable = true)\n",
      " |-- MaximumWindGustMs: double (nullable = true)\n",
      " |-- HourlyWindSpeedMs: double (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Station: string (nullable = true)\n",
      " |-- StationCode: string (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- AverageTemperatureC: double (nullable = true)\n",
      " |-- unscaled_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fazer as previsões\n",
    "df_prediction = pipeline_model.transform(df_validation)\n",
    "\n",
    "# verificar o schema\n",
    "df_prediction.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz previsões utilizando o modelo carregado anteriormente e aplica essas previsões ao conjunto de dados de validação. Depois, faz print do schema do dataframe resultante para verificar a estrutura dos dados previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+------------------+-------------------+\n",
      "|features                                                                                       |prediction        |AverageTemperatureC|\n",
      "+-----------------------------------------------------------------------------------------------+------------------+-------------------+\n",
      "|[0.0,26.784536226022087,4.389901860146138,3.8168979116104427,0.5299651423741525]               |25.047309782806053|25.35              |\n",
      "|[0.47455989094119655,25.582837192950308,3.885798297258544,4.461309247336881,1.1006968341617014]|21.756493704904262|20.85              |\n",
      "|[0.0,23.312961241592504,3.1926558982881006,3.8168979116104427,1.1516550209284466]              |19.300048413997672|19.1               |\n",
      "|[0.0,24.72829565832149,4.179858708942974,4.510879350085069,2.017944195963119]                  |20.825945326988112|21.95              |\n",
      "|[0.0,26.864649494893538,4.725970902071202,4.015178322603193,0.19364110971363263]               |25.649673982869338|26.15              |\n",
      "|[0.790933151568661,25.582837192950308,3.885798297258544,4.510879350085069,1.202613207695192]   |21.756493704904262|20.1               |\n",
      "|[0.0,26.06351680617902,4.347893229905505,4.064748425351381,1.6102787018291556]                 |23.9731929433541  |24.2               |\n",
      "|[0.0,25.876585845478964,4.26387596942424,4.26302883634413,0.713414614734436]                   |22.866004642307637|22.85              |\n",
      "|[0.0,26.83794507193639,4.746975217191519,4.26302883634413,3.597647985732227]                   |24.292467251783712|25.15              |\n",
      "|[0.0,25.849881422521815,4.26387596942424,4.26302883634413,0.7337978894411342]                  |22.866004642307637|22.85              |\n",
      "|[0.0,26.223743343921925,3.9278069274991765,4.163888630847755,1.192421570341843]                |23.150436491459285|22.6               |\n",
      "|[0.0,26.83794507193639,4.683962271830569,4.362169041840506,3.23074904101166]                   |24.07349105106497 |24.75              |\n",
      "|[2.5309860850197152,25.55613276999316,3.9068026123788604,4.610019555581443,1.3962543174088249] |21.520816852383327|19.65              |\n",
      "|[0.0,25.876585845478964,3.948811242619493,3.7177577061140674,1.4777874162356175]               |23.4645283446759  |24.1               |\n",
      "|[0.0,25.876585845478964,4.011824187980443,4.1143185280995676,1.3452961306420794]               |22.712577026104046|22.9               |\n",
      "|[0.0,26.704422957150634,4.284880284544556,4.312598939092318,3.2511323157183583]                |23.009466844344818|22.9               |\n",
      "|[0.0,25.66295046182176,4.494923435747721,4.610019555581443,1.8039198115427881]                 |22.693568922230675|22.549999999999997 |\n",
      "|[0.0,25.903290268436116,3.885798297258544,4.1143185280995676,1.0191637353349086]               |22.433890772126368|21.950000000000003 |\n",
      "|[0.0,25.956699114350418,3.5497292553334803,3.420337089624942,1.070121922101654]                |21.77674939658815 |23.049999999999997 |\n",
      "|[0.0,26.651014111236332,4.179858708942974,4.560449452833256,2.028135833316468]                 |23.009466844344818|21.450000000000003 |\n",
      "+-----------------------------------------------------------------------------------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verificar as previsões vs resultados reais\n",
    "df_prediction.select('features', 'prediction', 'AverageTemperatureC').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona as colunas `features`, `prediction` e `AverageTemperatureC` do dataframe de previsões e exibe os valores, em prol de comparar as previsões do modelo com os resultados reais da temperatura média, obtendo valores muito semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas no conjunto de validação:\n",
      "Validation Metric rmse = 2.348234359432686\n",
      "Validation Metric mse = 5.514204606820237\n",
      "Validation Metric mae = 1.6548994294137063\n",
      "Validation Metric r2 = 0.8193569327069066\n"
     ]
    }
   ],
   "source": [
    "# Previsões no conjunto de validação\n",
    "df_validation_prediction = pipeline_model.transform(df_validation)\n",
    "\n",
    "# Calcular métricas no conjunto de validação\n",
    "print(\"\\nMétricas no conjunto de validação:\")\n",
    "for metric in [\"rmse\", \"mse\", \"mae\", \"r2\"]:\n",
    "    evaluator = RegressionEvaluator(labelCol=\"AverageTemperatureC\", \n",
    "                                    predictionCol=\"prediction\", \n",
    "                                    metricName=metric)\n",
    "    value = evaluator.evaluate(df_validation_prediction)\n",
    "    print(f\"Validation Metric {metric} = {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os resultados obtidos nos dois conjuntos de métricas (com o notebook anterior), observamos que as métricas de validação e teste apresentam valores muito próximos entre si. Isso sugere que o modelo tem uma capacidade consistente de generalização, ou seja, ele é capaz de fazer previsões precisas tanto em dados que ele já viu como em dados novos (conjunto de validação).\n",
    "\n",
    "Concluímos que o modelo de regressão foi bem ajustado aos dados de temperatura, com valores de RMSE, MSE e MAE em torno de 2°C e um R² de aproximadamente 0.82, indicando que cerca de 82% da variabilidade nos dados é explicada pelo modelo. Isso sugere que o modelo é robusto e pode ser aplicado com confiança para prever a temperatura média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar os resultados\n",
    "df_prediction.write.mode(\"overwrite\").parquet(\"regression_model_results.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados das previsões feitas pelo modelo de regressão foram gravados no formato Parquet no arquivo 'regression_model_results.parquet'. O modo 'overwrite' foi utilizado para substituir qualquer arquivo existente com o mesmo nome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão da precipitação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os dados de validação do arquivo Parquet\n",
    "df_validation = spark.read.parquet(\"classification-validation-set.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados de validação do arquivo Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o pipeline treinado do disco\n",
    "pipeline_model = TrainValidationSplitModel.load(\"model-svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o pipeline treinado do disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- HourlyStationLevelAtmosphericPressureMb: double (nullable = true)\n",
      " |-- LastHourMaxAtmosphericPressureMb: double (nullable = true)\n",
      " |-- LastHourMinAtmosphericPressureMb: double (nullable = true)\n",
      " |-- HourlyDryBulbAirTemperatureC: double (nullable = true)\n",
      " |-- DewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMaxDewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMinDewPointTemperatureC: double (nullable = true)\n",
      " |-- LastHourMaxRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- LastHourMinRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- HourlyRelativeHumidityPercentage: integer (nullable = true)\n",
      " |-- HourlyWindDirectionRadiusDegrees: integer (nullable = true)\n",
      " |-- MaximumWindGustMs: double (nullable = true)\n",
      " |-- HourlyWindSpeedMs: double (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Station: string (nullable = true)\n",
      " |-- StationCode: string (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- AverageTemperatureC: double (nullable = true)\n",
      " |-- Rains: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fazer as previsões\n",
    "df_prediction = pipeline_model.transform(df_validation)\n",
    "\n",
    "# verificar o schema\n",
    "df_prediction.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz previsões utilizando o modelo de pipeline treinado anteriormente no conjunto de validação e faz print da estrutura do dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------+-----+\n",
      "|features                                  |prediction|Rains|\n",
      "+------------------------------------------+----------+-----+\n",
      "|[964.1,21.5,89.0,56.0,24.25]              |1.0       |1    |\n",
      "|[919.1,20.0,89.0,338.0,22.2]              |1.0       |1    |\n",
      "|[968.8,20.7,93.0,201.0,22.7]              |1.0       |1    |\n",
      "|[978.8,22.5,95.0,246.0,23.4]              |1.0       |1    |\n",
      "|[963.2,22.8,96.0,99.0,23.85]              |1.0       |1    |\n",
      "|[1014.1,19.9,93.0,223.0,21.35]            |1.0       |1    |\n",
      "|[963.2,20.6,85.0,65.0,23.299999999999997] |1.0       |1    |\n",
      "|[968.6,21.3,96.0,320.0,22.0]              |1.0       |1    |\n",
      "|[966.7,20.5,95.0,323.0,21.299999999999997]|1.0       |1    |\n",
      "|[954.3,21.9,96.0,66.0,22.7]               |1.0       |1    |\n",
      "|[918.7,20.5,92.0,338.0,21.450000000000003]|1.0       |1    |\n",
      "|[956.6,22.9,95.0,69.0,23.55]              |1.0       |1    |\n",
      "|[956.3,22.8,93.0,73.0,24.1]               |1.0       |1    |\n",
      "|[969.0,21.3,87.0,22.0,23.35]              |1.0       |1    |\n",
      "|[990.7,25.0,78.0,329.0,28.35]             |0.0       |1    |\n",
      "|[997.0,24.4,74.0,340.0,29.35]             |0.0       |1    |\n",
      "|[951.3,21.4,73.0,290.0,26.85]             |0.0       |1    |\n",
      "|[963.5,23.6,90.0,87.0,24.950000000000003] |1.0       |1    |\n",
      "|[941.9,22.2,84.0,308.0,24.2]              |1.0       |1    |\n",
      "|[958.5,24.0,79.0,10.0,26.3]               |0.0       |1    |\n",
      "+------------------------------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prediction.select('features', 'prediction', 'Rains').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona e exibe as `features`, `prediction` e `Rains` do dataframe resultante das previsões para comparar as previsões com os valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 467559\n",
      "True Negatives (TN): 350826\n",
      "False Positives (FP): 181671\n",
      "False Negatives (FN): 66212\n",
      "Total: 1066268\n"
     ]
    }
   ],
   "source": [
    "# obter os TN, TP, FP, FN\n",
    "n = df_prediction.count()\n",
    "tp = df_prediction.filter((F.col('Rains') == 1) & (F.col('prediction') == 1.0)).count()\n",
    "tn = df_prediction.filter((F.col('Rains') == 0) & (F.col('prediction') == 0.0)).count()\n",
    "fp = df_prediction.filter((F.col('Rains') == 0) & (F.col('prediction') == 1.0)).count()\n",
    "fn = df_prediction.filter((F.col('Rains') == 1) & (F.col('prediction') == 0.0)).count()\n",
    "\n",
    "print(\"True Positives (TP):\", tp)\n",
    "print(\"True Negatives (TN):\", tn)\n",
    "print(\"False Positives (FP):\", fp)\n",
    "print(\"False Negatives (FN):\", fn)\n",
    "print(\"Total:\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código calcula e exibe True Positives, True Negatives, False Positives, False Negatives, e o total de previsões, indicando o desempenho do modelo ao prever a ocorrência de chuva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8345782967295283\n",
      "Accuracy: 0.7675227991461809\n",
      "Recall: 0.7675227991461808\n",
      "Precision: 0.780631359569111\n",
      "F1 Score: 0.7647334317699119\n"
     ]
    }
   ],
   "source": [
    "# avaliar o modelo com recurso à AUC \n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"Rains\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = binary_evaluator.evaluate(df_prediction)\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# outras métricas de performance do modelo\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Rains\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(df_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "recall = evaluator.evaluate(df_prediction, {evaluator.metricName: \"weightedRecall\"})\n",
    "precision = evaluator.evaluate(df_prediction, {evaluator.metricName: \"weightedPrecision\"})\n",
    "f1 = evaluator.evaluate(df_prediction, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados das avaliações do modelo de classificação nos dois conjuntos (ao comparar com o notebook anterior) são bastante semelhantes. Ambos apresentam métricas de desempenho como AUC, precisão, recall, e F1 Score com valores muito próximos. Isso indica que o desempenho do modelo é consistente entre os conjuntos de dados de validação utilizados, sugerindo uma performance robusta e estável na previsão da ocorrência de chuva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.write.mode(\"overwrite\").parquet(\"classification_model_results.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda as previsões feitas pelo modelo de classificação no conjunto de dados de validação em um arquivo Parquet chamado \"classification_model_results.parquet\", substituindo qualquer arquivo existente com o mesmo nome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
